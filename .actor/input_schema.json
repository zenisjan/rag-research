{
    "title": "Interviews RAG",
    "description": "RAG Actor for querying meeting notes. Configuration is loaded from environment variables (OPENAI_API_KEY, PINECONE_API_KEY, INDEX_NAME). HTTP requests can override API keys and other settings per-request.",
    "type": "object",
    "schemaVersion": 1,
    "properties": {
        "question": {
            "title": "Question",
            "type": "string",
            "description": "Your question about the meeting notes/interviews. Provide via HTTP POST to /query endpoint.",
            "editor": "textarea"
        },
        "openai_api_key": {
            "title": "OpenAI API Key",
            "type": "string",
            "description": "OpenAI API key. Optional per-request override (uses environment variable if not provided).",
            "editor": "textfield",
            "isSecret": true
        },
        "pinecone_api_key": {
            "title": "Pinecone API Key",
            "type": "string",
            "description": "Pinecone API key. Optional per-request override (uses environment variable if not provided).",
            "editor": "textfield",
            "isSecret": true
        },
        "index_name": {
            "title": "Pinecone Index Name",
            "type": "string",
            "description": "Name of the Pinecone index to query. Optional per-request override (uses environment variable if not provided).",
            "editor": "textfield"
        },
        "llm_model": {
            "title": "LLM Model",
            "type": "string",
            "description": "OpenAI model to use for generating answers. Optional per-request override.",
            "editor": "select",
            "default": "gpt-4o",
            "enum": ["gpt-5.2","gpt-5.1","gpt-4o", "gpt-4o-mini", "gpt-4-turbo", "gpt-4", "gpt-3.5-turbo", "o1", "o1-mini", "o3-mini"],
            "enumTitles": ["gpt-5.2","gpt-5.1","GPT-4o", "GPT-4o Mini", "GPT-4 Turbo", "GPT-4", "GPT-3.5 Turbo", "O1", "O1 Mini", "O3 Mini"]
        },
        "k": {
            "title": "Top K Results",
            "type": "integer",
            "description": "Number of documents to retrieve (1-50). Optional per-request override.",
            "editor": "number",
            "default": 20,
            "minimum": 1,
            "maximum": 50
        },
        "threshold": {
            "title": "Similarity Threshold",
            "type": "number",
            "description": "Minimum similarity score for retrieved documents (0.0-1.0). Optional per-request override.",
            "editor": "number",
            "default": 0.3,
            "minimum": 0,
            "maximum": 1
        },
        "recency_weight": {
            "title": "Recency Weight",
            "type": "number",
            "description": "How much to favor recent documents (0.0 = only similarity, 1.0 = only recency). Optional per-request override.",
            "editor": "number",
            "default": 0.2,
            "minimum": 0,
            "maximum": 1
        },
        "recency_decay_days": {
            "title": "Recency Decay (Days)",
            "type": "integer",
            "description": "Half-life for recency scoring. Optional per-request override.",
            "editor": "number",
            "default": 180,
            "minimum": 1,
            "maximum": 3650
        },
        "start_template": {
            "title": "System Prompt",
            "type": "string",
            "description": "Instructions for how the AI should respond. Optional per-request override.",
            "editor": "textarea",
            "default": "Answer the question based on the context provided."
        }
    },
    "required": ["question"]
}
